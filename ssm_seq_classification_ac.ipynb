{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0605ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayushman/miniconda3/envs/py310/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/ayushman/miniconda3/envs/py310/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c106detail14torchCheckFailEPKcS2_jRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/ayushman/miniconda3/envs/py310/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/ayushman/miniconda3/envs/py310/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c106detail14torchCheckFailEPKcS2_jRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_undirected\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from ssm_utlis import set_seed\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm \n",
    "#set_seed(21)\n",
    "\n",
    "class CTDGraphDataset(Dataset):\n",
    "    def __init__(self, N, M, seed=42):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            N (int): number of edges per sequence\n",
    "            M (int): number of sequences\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        for _ in range(M):\n",
    "            # node 0 signal = label\n",
    "            y = np.random.choice([0, 1])\n",
    "            self.labels.append(y)\n",
    "\n",
    "            # node signals\n",
    "            signals = {0: float(y)*2-1}\n",
    "            for i in range(1, N + 1):\n",
    "                signals[i] = np.random.uniform(-1, 1)\n",
    "\n",
    "            # edges\n",
    "            src = np.arange(0, N)\n",
    "            dst = np.arange(1, N + 1)\n",
    "            times = np.sort(np.random.uniform(0, 10, N))  # increasing times\n",
    "\n",
    "            # endpoint signals\n",
    "            x_src = np.array([signals[s] for s in src])\n",
    "            x_dst = np.array([signals[d] for d in dst])\n",
    "\n",
    "            self.data.append((src, dst, times, x_src, x_dst))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.M\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, dst, times, x_src, x_dst = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        return {\n",
    "            \"src\": torch.tensor(src, dtype=torch.long),\n",
    "            \"dst\": torch.tensor(dst, dtype=torch.long),\n",
    "            \"t\": torch.tensor(times, dtype=torch.float32),\n",
    "            \"x_src\": torch.tensor(x_src, dtype=torch.float32),\n",
    "            \"x_dst\": torch.tensor(x_dst, dtype=torch.float32),\n",
    "            \"y\": torch.tensor(y, dtype=torch.float32)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d9526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "def get_loaders(N, M, batch_size=4, train_split=0.7, val_split=0.15):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        N (int): number of nodes (dataset-specific param for CTDGraphDataset).\n",
    "        M (int): number of samples.\n",
    "        batch_size (int): batch size for loaders.\n",
    "        train_split (float): fraction of data to use for training.\n",
    "        val_split (float): fraction of data to use for validation.\n",
    "        seed (int): random seed.\n",
    "        \n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader\n",
    "    \"\"\"\n",
    "    dataset = CTDGraphDataset(N, M)\n",
    "\n",
    "    # sizes\n",
    "    train_size = int(train_split * M)\n",
    "    val_size = int(val_split * M)\n",
    "    test_size = M - (train_size + val_size)\n",
    "\n",
    "    # make sure the total matches exactly\n",
    "    assert train_size + val_size + test_size == M, \"Split sizes must sum to dataset size\"\n",
    "\n",
    "    # split\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size], generator=torch.Generator()\n",
    "    )\n",
    "\n",
    "    # loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6de7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.0, path=\"best_model_sq.pt\"):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_acc = -float(\"inf\")\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.path = path  # save checkpoint\n",
    "\n",
    "    def __call__(self, acc, model):\n",
    "        if acc > self.best_acc + self.delta:\n",
    "            self.best_acc = acc\n",
    "            self.counter = 0\n",
    "            # save model checkpoint\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b8720d",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1d9819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 9\n",
    "M=1000\n",
    "batch_size = 400\n",
    "train_loader,val_laoder,test_loader = get_loaders(N=N,M=M,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049bacd",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f9bfd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(10)\n",
    "torch.hstack([a,a]).view(2*10,-1).view(2,10,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c19eddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Embeddings: Nil\n"
     ]
    }
   ],
   "source": [
    "from ssm_memory import MemoryModel\n",
    "state_dim =32\n",
    "time_dim = 4\n",
    "device = 'cuda'\n",
    "lr = 1e-3\n",
    "epochs = 1600\n",
    "model = MemoryModel(num_nodes=N+1,input_dim=1,hidden_dim=state_dim,time_dim=time_dim,reg=1e-4,device=device,update_type='mamba').to(device)\n",
    "path = 'sq_mod.pt'\n",
    "early_stopper = EarlyStopping(patience=500, delta=1e-3,path=path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35217dd8",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b099b3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3829d787f3b347a2a65eb2fe1c33103c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1600 | Loss: 1.3864 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 2/1600 | Loss: 1.3865 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 3/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 4/1600 | Loss: 1.3862 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 5/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 6/1600 | Loss: 1.3859 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 7/1600 | Loss: 1.3859 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 8/1600 | Loss: 1.3859 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 9/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 10/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 11/1600 | Loss: 1.3859 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 12/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 13/1600 | Loss: 1.3863 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 14/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 15/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 16/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 17/1600 | Loss: 1.3862 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 18/1600 | Loss: 1.3862 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 19/1600 | Loss: 1.3859 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 20/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 21/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 22/1600 | Loss: 1.3862 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 23/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 24/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 25/1600 | Loss: 1.3862 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 26/1600 | Loss: 1.3862 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 27/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 28/1600 | Loss: 1.3862 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 29/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 30/1600 | Loss: 1.3859 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 31/1600 | Loss: 1.3864 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 32/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 33/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 34/1600 | Loss: 1.3866 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 35/1600 | Loss: 1.3860 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 36/1600 | Loss: 1.3862 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 37/1600 | Loss: 1.3861 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Epoch 38/1600 | Loss: 1.3859 |Train Acc: 0.5071| Val Acc: 0.4733\n",
      "Early stopping at epoch 38\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=1e-3)\n",
    "\n",
    "In = torch.eye(4).to(device)\n",
    "A = In.clone()\n",
    "e = [(0,1),(0,2),(2,3)]\n",
    "\n",
    "for u,v in e:\n",
    "    A[u,v] = 1\n",
    "    A[v,u] = 1\n",
    "D = torch.sum(A,dim=-1)\n",
    "D[D==0]=1\n",
    "D =  torch.diag(D**-(1/2))\n",
    "L_t = In - D@A@D\n",
    "\n",
    "ep = [(0,2),(2,3)]\n",
    "Ap = In.clone()\n",
    "for u,v in ep:\n",
    "    Ap[u,v] = 1\n",
    "    Ap[v,u] = 1\n",
    "\n",
    "D = torch.sum(Ap,dim=-1)\n",
    "D[D==0]=1\n",
    "D =  torch.diag(D**-(1/2))\n",
    "\n",
    "L_p = In - D@Ap@D\n",
    "Id   = torch.eye(state_dim,device='cuda')\n",
    "delta = 1/N+1\n",
    "for epoch in tqdm(range(epochs),desc='Epochs: '):\n",
    "    model.train()\n",
    "    total_loss, total_score, total_samples = 0, [], []\n",
    "    pred = []\n",
    "    hidden_state_list = []\n",
    "    # yt = torch.zeros((len(train_loader),1),device=model.device)\n",
    "    neighbour = 0\n",
    "    thresholds = 0\n",
    "    for bid,batch in enumerate(train_loader):\n",
    "        src, dst = batch[\"src\"].to(device), batch[\"dst\"].to(device)\n",
    "        batch_size = src.shape[0]\n",
    "        \n",
    "        batch_ids = torch.arange(src.shape[0],device=device)\n",
    "        x_src, x_dst, y = batch[\"x_src\"].to(device), batch[\"x_dst\"].to(device), batch[\"y\"].to(device)\n",
    "        src_b,dst_b = src+batch_ids[:,None],dst+batch_ids[:,None]\n",
    "        m1_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "        ne_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "        # edge_index = torch.stack([torch.arange(batch_size*model.num_nodes,device=model.device),torch.arange(batch_size*model.num_nodes,device=model.device)])\n",
    "        for t in range(src.shape[-1]):\n",
    "            src_t = src_b[:,t]\n",
    "            dst_t = dst_b[:,t]\n",
    "            \n",
    "            # current_edge_index = to_undirected(torch.cat([edge_index,new_edges],dim=1))\n",
    "            K = 2\n",
    "            last_id = torch.clamp_min(src[0,t]-K,min=0).to(torch.int).item()\n",
    "              \n",
    "            active = torch.arange(last_id,dst[0,t]+1).to(device)\n",
    "            ax = len(active)\n",
    "            if ax<4:\n",
    "                zero_ids = 4-len(active)\n",
    "                active = torch.hstack([active,torch.zeros(zero_ids,).to(device).to(torch.int)])\n",
    "            x_t = torch.zeros((batch_size,len(active),model.input_dim),device=model.device)\n",
    "            # x_n =  torch.zeros((batch_size,2,model.hidden_dim),device=model.device)\n",
    "            # L_t = torch.eye(dst[0,t]+1).to(device)\n",
    "            # L_t[src[0,:t+1],dst[0,:t+1]]=1\n",
    "            # L_t[dst[0,:t+1],src[0,:t+1]]=1\n",
    "            # D = torch.diag(torch.sum(L_t,dim=1)**(-0.5))\n",
    "            # L_t = torch.eye(len(L_t)).to(device) - D@L_t@D\n",
    "\n",
    "            # L_p = torch.eye(len(L_t)).to(device)\n",
    "            # if t>0:\n",
    "                # L_p[src[0,:t],dst[0,:t]]=1\n",
    "                # L_p[dst[0,:t],src[0,:t]]=1\n",
    "                # D = torch.diag(torch.sum(L_p,dim=1)**(-0.5))\n",
    "                # L_p = torch.eye(len(L_t)).to(device) - D@L_p@D\n",
    "                \n",
    "            # Fill Data to Current Node\n",
    "            if ax<4:\n",
    "                for k in range(2,4-ax+1):\n",
    "                    x_t[:,k] = x_src[:,0].unsqueeze(-1)\n",
    "                \n",
    "            x_t[:,0]= x_src[:,t].unsqueeze(-1)\n",
    "            x_t[:,1]= x_dst[:,t].unsqueeze(-1)\n",
    "\n",
    "            \n",
    "            prev_c_1= m1_vec[:,active].view((batch_size*(len(active)),-1))\n",
    "            x_batch = x_t.view(batch_size*len(active),-1)\n",
    "            zt = model.TuneInputSC(x_batch) # input Tuning / Selective Scan\n",
    "            \n",
    "            A = model.A_\n",
    "            At_ = torch.matrix_exp(-A.T*delta)\n",
    "            reg = 1\n",
    "            In = torch.eye(len(active)).to(device)\n",
    "            PL_ = In + reg*L_t + L_t@L_t\n",
    "            PL_p = In + reg*L_p + + L_p@L_p                             \n",
    "\n",
    "            PL_inv = torch.linalg.inv(PL_)\n",
    "            A_s= In - PL_inv@PL_p\n",
    "            PL_b = torch.block_diag(*PL_inv[None,:,:].repeat(batch_size,1,1))\n",
    "            A_sb = torch.block_diag(*A_s.unsqueeze(0).repeat(batch_size,1,1))\n",
    "            updated_c_1=  -A_sb@ prev_c_1 +  prev_c_1 @ At_  +  PL_b @ zt\n",
    "            final_state = updated_c_1\n",
    "\n",
    "            m1_vec[:,active] = updated_c_1.view(batch_size,len(active),-1)\n",
    "            ne_vec[:,active] = final_state.view(batch_size,len(active),-1)\n",
    "\n",
    "            # edge_index = current_edge_index.clone()\n",
    "\n",
    "        hidden_state_list.append(ne_vec)\n",
    "        logits = model.SeqClass(hidden_state_list[-1][:,-1]).view(-1)\n",
    "        loss = criterion(target = y,input=logits) #+ torch.norm(model.A_hippo-model.A_,p=2)*1e-1\n",
    "        total_loss += loss #/ batch_size\n",
    "        # preds = ( logits> 0).float()\n",
    "        pred += (logits>0).to(int).tolist()\n",
    "        total_score += logits.tolist()\n",
    "        total_samples += y.tolist()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "   \n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    v_score, v_samples =  [], []\n",
    "    v_pred = []\n",
    "    hidden_state_list = []\n",
    "    # yt = torch.zeros((len(train_loader),1),device=model.device)\n",
    "    neighbour = 0\n",
    "    thresholds = 0\n",
    "    with torch.no_grad():\n",
    "        for bid,batch in enumerate(val_laoder):\n",
    "            src, dst = batch[\"src\"].to(device), batch[\"dst\"].to(device)\n",
    "            batch_size = src.shape[0]\n",
    "            \n",
    "            batch_ids = torch.arange(src.shape[0],device=device)\n",
    "            x_src, x_dst, y = batch[\"x_src\"].to(device), batch[\"x_dst\"].to(device), batch[\"y\"].to(device)\n",
    "            src_b,dst_b = src+batch_ids[:,None],dst+batch_ids[:,None]\n",
    "            m1_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "            ne_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "            # edge_index = torch.stack([torch.arange(batch_size*model.num_nodes,device=model.device),torch.arange(batch_size*model.num_nodes,device=model.device)])\n",
    "            for t in range(src.shape[-1]):\n",
    "                src_t = src_b[:,t]\n",
    "                dst_t = dst_b[:,t]\n",
    "                \n",
    "                # current_edge_index = to_undirected(torch.cat([edge_index,new_edges],dim=1))\n",
    "                K = 2\n",
    "                last_id = torch.clamp_min(src[0,t]-K,min=0).to(torch.int).item()\n",
    "                \n",
    "                active = torch.arange(last_id,dst[0,t]+1).to(device)\n",
    "                ax = len(active)\n",
    "                if ax<4:\n",
    "                    zero_ids = 4-len(active)\n",
    "                    active = torch.hstack([active,torch.zeros(zero_ids,).to(device).to(torch.int)])\n",
    "                x_t = torch.zeros((batch_size,len(active),model.input_dim),device=model.device)\n",
    "                # x_n =  torch.zeros((batch_size,2,model.hidden_dim),device=model.device)\n",
    "                # L_t = torch.eye(dst[0,t]+1).to(device)\n",
    "                # L_t[src[0,:t+1],dst[0,:t+1]]=1\n",
    "                # L_t[dst[0,:t+1],src[0,:t+1]]=1\n",
    "                # D = torch.diag(torch.sum(L_t,dim=1)**(-0.5))\n",
    "                # L_t = torch.eye(len(L_t)).to(device) - D@L_t@D\n",
    "\n",
    "                # L_p = torch.eye(len(L_t)).to(device)\n",
    "                # if t>0:\n",
    "                    # L_p[src[0,:t],dst[0,:t]]=1\n",
    "                    # L_p[dst[0,:t],src[0,:t]]=1\n",
    "                    # D = torch.diag(torch.sum(L_p,dim=1)**(-0.5))\n",
    "                    # L_p = torch.eye(len(L_t)).to(device) - D@L_p@D\n",
    "                    \n",
    "                # Fill Data to Current Node\n",
    "                # if ax<4:\n",
    "                #     for k in range(2,4-ax+1):\n",
    "                #         x_t[:,k] = x_src[:,0].unsqueeze(-1)\n",
    "                    \n",
    "                x_t[:,0]= x_src[:,t].unsqueeze(-1)\n",
    "                x_t[:,1]= x_dst[:,t].unsqueeze(-1)\n",
    "\n",
    "                \n",
    "                prev_c_1= m1_vec[:,active].view((batch_size*(len(active)),-1))\n",
    "                x_batch = x_t.view(batch_size*len(active),-1)\n",
    "                zt = model.TuneInputSC(x_batch) # input Tuning / Selective Scan\n",
    "                \n",
    "                A = model.A_\n",
    "                At_ = torch.matrix_exp(-A.T*delta)\n",
    "                reg = 1\n",
    "                In = torch.eye(len(active)).to(device)\n",
    "                PL_ = In + reg*L_t + L_t@L_t\n",
    "                PL_p = In + reg*L_p + + L_p@L_p                             \n",
    "\n",
    "                PL_inv = torch.linalg.inv(PL_)\n",
    "                A_s= In - PL_inv@PL_p\n",
    "                PL_b = torch.block_diag(*PL_inv[None,:,:].repeat(batch_size,1,1))\n",
    "                A_sb = torch.block_diag(*A_s.unsqueeze(0).repeat(batch_size,1,1))\n",
    "                updated_c_1=  -A_sb@ prev_c_1 +  prev_c_1 @ At_  +  PL_b @ zt\n",
    "                final_state = updated_c_1\n",
    "\n",
    "                m1_vec[:,active] = updated_c_1.view(batch_size,len(active),-1)\n",
    "                ne_vec[:,active] = final_state.view(batch_size,len(active),-1)\n",
    "\n",
    "\n",
    "\n",
    "                # edge_index = current_edge_index.clone()\n",
    "\n",
    "            hidden_state_list.append(ne_vec)\n",
    "            logits = model.SeqClass(hidden_state_list[-1][:,-1]).view(-1)\n",
    "            # preds = ( logits> 0).float()\n",
    "            v_pred += (logits>0).to(int).tolist()\n",
    "            v_score += logits.tolist()\n",
    "            v_samples += y.tolist()\n",
    "\n",
    "    val_acc = accuracy_score(v_pred,v_samples)\n",
    "    auc = roc_auc_score(total_samples,total_score)\n",
    "    acc = accuracy_score(pred,total_samples)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f} |Train Acc: {acc:.4f}| Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    early_stopper(val_acc, model)\n",
    "    if early_stopper.early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe52e56",
   "metadata": {},
   "source": [
    "best_t,best_acc = find_best_threshold(total_samples,total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd54a402",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (45451634.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[43], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    ne_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=mode l.device)\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(path,weights_only=True))\n",
    "model.eval()\n",
    "total_loss, total_score, total_samples = 0,[], []\n",
    "hidden_state_list = []\n",
    "pred = []\n",
    "yt = []\n",
    "\n",
    "for bid,batch in enumerate(test_loader):\n",
    "    src, dst = batch[\"src\"].to(device), batch[\"dst\"].to(device)\n",
    "    batch_size = src.shape[0]\n",
    "    batch_ids = torch.arange(src.shape[0],device=device)\n",
    "    x_src, x_dst, y = batch[\"x_src\"].to(device), batch[\"x_dst\"].to(device), batch[\"y\"].to(device)\n",
    "    src_b,dst_b = src+batch_ids[:,None],dst+batch_ids[:,None]\n",
    "    m1_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "    ne_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=mode l.device)\n",
    "    # edge_index = torch.stack([torch.arange(batch_size*model.num_nodes,device=model.device),torch.arange(batch_size*model.num_nodes,device=model.device)])\n",
    "    for t in range(src.shape[-1]):\n",
    "        src_t = src_b[:,t]\n",
    "        dst_t = dst_b[:,t]\n",
    "        # current_edge_index = to_undirected(torch.cat([edge_index,new_edges],dim=1))\n",
    "        active = torch.hstack([src[0,t],dst[0,t]])\n",
    "        x_t = torch.zeros((batch_size,3,model.input_dim),device=model.device)\n",
    "        # x_n =  torch.zeros((batch_size,2,model.hidden_dim),device=model.device)\n",
    "        \n",
    "        # Fill Data to Current Node\n",
    "        x_t[:,0]= x_src[:,t].unsqueeze(-1)\n",
    "        x_t[:,1]= x_dst[:,t].unsqueeze(-1)\n",
    "\n",
    "        if t>=1:\n",
    "            x_t[:,2]= x_src[:,t-1].unsqueeze(-1)\n",
    "            active = torch.hstack([active,src[0,t-1]])\n",
    "        else:\n",
    "            x_t[:,2]= x_src[:,0].unsqueeze(-1)\n",
    "            active = torch.hstack([active,src[0,0]])\n",
    "\n",
    "        prev_c_1= m1_vec[:,active].view((batch_size*3,-1))\n",
    "        x_batch = x_t.view(batch_size*3,-1)\n",
    "        zt = model.TuneInputSC(x_batch) # input Tuning / Selective Scan\n",
    "        # gate = model.B_gate_a(zt)\n",
    "        # ztn = F.sigmoid(gate)*zt\n",
    "        Bzt = zt #model.B1(zt)\n",
    "        # delta_1 = torch.ones((zt.shape[0],model.hidden_dim),device=model.device)\n",
    "        # A_cont_1 = -torch.exp(model.A_log_1) \n",
    "        # At_bar_1 = torch.exp(delta_1 * A_cont_1) \n",
    "        At_ = Id - model.A_.T*delta\n",
    "\n",
    "        reg = 1\n",
    "        \n",
    "        # C_1 = ((Bzt * delta))[None]*t_weights[:,None,None] \n",
    "        # RHS_ = C_1@torch.matrix_exp((model.A_.T*delta)[None] * t_nodes[:,None,None])\n",
    "        \n",
    "        \n",
    "        PL_inv = torch.linalg.inv(In+reg*L_t)\n",
    "        PL_prev = In*(1+reg)\n",
    "        s  =  (In + PL_inv@PL_prev)\n",
    "        A_s= PL_inv@(reg*del_L)\n",
    "\n",
    "        PL_b = torch.block_diag(*PL_inv[None,:,:].repeat(batch_size,1,1))\n",
    "        # A_st = torch.matrix_exp(s*t_nodes[:,None,None])\n",
    "        A_sb = torch.block_diag(*A_s.unsqueeze(0).repeat(batch_size,1,1))\n",
    "        # A_stb = torch.stack([torch.block_diag(*s) for s in A_st[:,None,:,:].repeat(1,batch_size,1,1)])\n",
    "        # integral_1 = torch.sum(A_stb@PL_b[None,:,:]@RHS_,dim=0)\n",
    "\n",
    "        updated_c_1=  -A_sb@ prev_c_1 +  prev_c_1 @ At_  +  PL_b @ Bzt\n",
    "\n",
    "        u_2 =  zt+F.gelu(updated_c_1,approximate='tanh')# + zt approximate for faster results, maybe less accurate\n",
    "        final_state = updated_c_1\n",
    "        m1_vec[:,active] = updated_c_1.view(batch_size,3,-1)\n",
    "        ne_vec[:,active] = final_state.view(batch_size,3,-1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_state_list.append(ne_vec)\n",
    "    logits = model.SeqClass(hidden_state_list[-1][:,-1]).view(-1)\n",
    "    total_score += logits.tolist()\n",
    "    total_samples += y.tolist()\n",
    "    pred += (logits>0).to(int).tolist()\n",
    "\n",
    "auc = roc_auc_score(total_samples,total_score)\n",
    "best_acc = accuracy_score(total_samples,pred)\n",
    "print(f\" Test Acc: {best_acc:.4f} |Test AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model Created\n",
      "Static Embeddings: Nil\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093eb5a18a1047389194aa7fd6c50f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 653\n",
      " Test Acc: 0.4533 |Test AUC: 0.4985\n",
      "New Model Created\n",
      "Static Embeddings: Nil\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33e7f517e9d4434945a234002df2f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 565\n",
      " Test Acc: 0.4867 |Test AUC: 0.4915\n",
      "New Model Created\n",
      "Static Embeddings: Nil\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39d9c1cb1e145168dd1f9e7a40ca73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 588\n",
      " Test Acc: 0.4800 |Test AUC: 0.4960\n",
      "New Model Created\n",
      "Static Embeddings: Nil\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02290203bab41c0992f743c21a5027e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m A_s\u001b[38;5;241m=\u001b[39m PL_inv\u001b[38;5;241m@\u001b[39m(reg\u001b[38;5;241m*\u001b[39mdel_L)\n\u001b[1;32m     83\u001b[0m PL_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mblock_diag(\u001b[38;5;241m*\u001b[39mPL_inv[\u001b[38;5;28;01mNone\u001b[39;00m,:,:]\u001b[38;5;241m.\u001b[39mrepeat(batch_size,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 84\u001b[0m A_sb \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_diag\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mA_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m updated_c_1\u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m-\u001b[39mA_sb\u001b[38;5;241m@\u001b[39m prev_c_1 \u001b[38;5;241m+\u001b[39m  prev_c_1 \u001b[38;5;241m@\u001b[39m At_  \u001b[38;5;241m+\u001b[39m  PL_b \u001b[38;5;241m@\u001b[39m zt\n\u001b[1;32m     86\u001b[0m final_state \u001b[38;5;241m=\u001b[39m updated_c_1\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_tensor.py:1119\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m   1111\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1118\u001b[0m     )\n\u001b[0;32m-> 1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Full TestBench\n",
    "delta = 1/20\n",
    "from ssm_memory import MemoryModel\n",
    "test_vals = []\n",
    "for _ in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    state_dim = 64\n",
    "    time_dim = 4\n",
    "    device = 'cuda'\n",
    "    lr = 1e-3\n",
    "    epochs = 2000\n",
    "    print('New Model Created')\n",
    "    model = MemoryModel(num_nodes=N+1,input_dim=1,hidden_dim=state_dim,time_dim=time_dim,reg=1e-4,device=device,update_type='mamba').to(device)\n",
    "    path = 'sq_mod.pt'\n",
    "    early_stopper = EarlyStopping(patience=500, delta=1e-3,path=path)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # for binary classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=1e-3)\n",
    "\n",
    "    In = torch.eye(3).to(device)\n",
    "    A = In.clone()\n",
    "    e = [(0,1),(0,2)]\n",
    "\n",
    "    for u,v in e:\n",
    "        A[u,v] = 1\n",
    "        A[v,u] = 1\n",
    "    D = torch.diag(torch.sum(A,dim=-1)**-(1/2))\n",
    "    L_t = In - D@A@D\n",
    "\n",
    "    ep = [(0,2)]\n",
    "    Ap = In.clone()\n",
    "    for u,v in ep:\n",
    "        Ap[u,v] = 1\n",
    "        Ap[v,u] = 1\n",
    "    D = torch.diag(torch.sum(Ap,dim=-1)**-(1/2))\n",
    "    L_p = In - D@Ap@D\n",
    "    del_L = L_t-L_p\n",
    "    Id   = torch.eye(state_dim,device='cuda')\n",
    "\n",
    "    for epoch in tqdm(range(epochs),desc='Epochs: '):\n",
    "        model.train()\n",
    "        total_loss, total_score, total_samples = 0, [], []\n",
    "        pred = []\n",
    "        hidden_state_list = []\n",
    "        # yt = torch.zeros((len(train_loader),1),device=model.device)\n",
    "        neighbour = 0\n",
    "        thresholds = 0\n",
    "        for bid,batch in enumerate(train_loader):\n",
    "            src, dst = batch[\"src\"].to(device), batch[\"dst\"].to(device)\n",
    "            batch_size = src.shape[0]\n",
    "            batch_ids = torch.arange(src.shape[0],device=device)\n",
    "            x_src, x_dst, y = batch[\"x_src\"].to(device), batch[\"x_dst\"].to(device), batch[\"y\"].to(device)\n",
    "            src_b,dst_b = src+batch_ids[:,None],dst+batch_ids[:,None]\n",
    "            m1_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "            ne_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "            # edge_index = torch.stack([torch.arange(batch_size*model.num_nodes,device=model.device),torch.arange(batch_size*model.num_nodes,device=model.device)])\n",
    "            for t in range(src.shape[-1]):\n",
    "                src_t = src_b[:,t]\n",
    "                dst_t = dst_b[:,t]\n",
    "                # current_edge_index = to_undirected(torch.cat([edge_index,new_edges],dim=1))\n",
    "                active = torch.hstack([src[0,t],dst[0,t]])\n",
    "                x_t = torch.zeros((batch_size,3,model.input_dim),device=model.device)\n",
    "                # x_n =  torch.zeros((batch_size,2,model.hidden_dim),device=model.device)\n",
    "                \n",
    "                # Fill Data to Current Node\n",
    "                x_t[:,0]= x_src[:,t].unsqueeze(-1)\n",
    "                x_t[:,1]= x_dst[:,t].unsqueeze(-1)\n",
    "\n",
    "                if t>=1:\n",
    "                    x_t[:,2]= x_src[:,t-1].unsqueeze(-1)\n",
    "                    active = torch.hstack([active,src[0,t-1]])\n",
    "                else:\n",
    "                    x_t[:,2]= x_src[:,0].unsqueeze(-1)\n",
    "                    active = torch.hstack([active,src[0,0]])\n",
    "\n",
    "                prev_c_1= m1_vec[:,active].view((batch_size*3,-1))\n",
    "                x_batch = x_t.view(batch_size*3,-1)\n",
    "                zt = model.TuneInputSC(x_batch) # input Tuning / Selective Scan\n",
    "                A = model.A_\n",
    "                At_ = Id - A.T*delta\n",
    "                reg = 1\n",
    "                PL_inv = torch.linalg.inv(In+reg*L_t)\n",
    "                A_s= PL_inv@(reg*del_L)\n",
    "                PL_b = torch.block_diag(*PL_inv[None,:,:].repeat(batch_size,1,1))\n",
    "                A_sb = torch.block_diag(*A_s.unsqueeze(0).repeat(batch_size,1,1))\n",
    "                updated_c_1=  -A_sb@ prev_c_1 +  prev_c_1 @ At_  +  PL_b @ zt\n",
    "                final_state = updated_c_1\n",
    "\n",
    "                m1_vec[:,active] = updated_c_1.view(batch_size,3,-1)\n",
    "                ne_vec[:,active] = final_state.view(batch_size,3,-1)\n",
    "\n",
    "                # edge_index = current_edge_index.clone()\n",
    "\n",
    "            hidden_state_list.append(ne_vec)\n",
    "            logits = model.SeqClass(hidden_state_list[-1][:,-1]).view(-1)\n",
    "            loss = criterion(target = y,input=logits) #+ torch.norm(model.A_hippo-model.A_,p=2)*1e-1\n",
    "            total_loss += loss #/ batch_size\n",
    "            # preds = ( logits> 0).float()\n",
    "            pred += (logits>0).to(int).tolist()\n",
    "            total_score += logits.tolist()\n",
    "            total_samples += y.tolist()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        v_score, v_samples =  [], []\n",
    "        v_pred = []\n",
    "        hidden_state_list = []\n",
    "        # yt = torch.zeros((len(train_loader),1),device=model.device)\n",
    "        neighbour = 0\n",
    "        thresholds = 0\n",
    "        with torch.no_grad():\n",
    "            for bid,batch in enumerate(val_laoder):\n",
    "                src, dst = batch[\"src\"].to(device), batch[\"dst\"].to(device)\n",
    "                batch_size = src.shape[0]\n",
    "                batch_ids = torch.arange(src.shape[0],device=device)\n",
    "                x_src, x_dst, y = batch[\"x_src\"].to(device), batch[\"x_dst\"].to(device), batch[\"y\"].to(device)\n",
    "                src_b,dst_b = src+batch_ids[:,None],dst+batch_ids[:,None]\n",
    "                m1_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "                ne_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "                # edge_index = torch.stack([torch.arange(batch_size*model.num_nodes,device=model.device),torch.arange(batch_size*model.num_nodes,device=model.device)])\n",
    "                for t in range(src.shape[-1]):\n",
    "                    src_t = src_b[:,t]\n",
    "                    dst_t = dst_b[:,t]\n",
    "                    # current_edge_index = to_undirected(torch.cat([edge_index,new_edges],dim=1))\n",
    "                    active = torch.hstack([src[0,t],dst[0,t]])\n",
    "                    x_t = torch.zeros((batch_size,3,model.input_dim),device=model.device)\n",
    "                    # x_n =  torch.zeros((batch_size,2,model.hidden_dim),device=model.device)\n",
    "                    \n",
    "                    # Fill Data to Current Node\n",
    "                    x_t[:,0]= x_src[:,t].unsqueeze(-1)\n",
    "                    x_t[:,1]= x_dst[:,t].unsqueeze(-1)\n",
    "\n",
    "                    if t>=1:\n",
    "                        x_t[:,2]= x_src[:,t-1].unsqueeze(-1)\n",
    "                        active = torch.hstack([active,src[0,t-1]])\n",
    "                    else:\n",
    "                        x_t[:,2]= x_src[:,0].unsqueeze(-1)\n",
    "                        active = torch.hstack([active,src[0,0]])\n",
    "\n",
    "                    prev_c_1= m1_vec[:,active].view((batch_size*3,-1))\n",
    "                    x_batch = x_t.view(batch_size*3,-1)\n",
    "                    zt = model.TuneInputSC(x_batch) # input Tuning / Selective Scan\n",
    "                    A = model.A_\n",
    "                    At_ = Id - A.T*delta\n",
    "                    reg = 1\n",
    "                    PL_inv = torch.linalg.inv(In+reg*L_t)\n",
    "                    A_s= PL_inv@(reg*del_L)\n",
    "                    PL_b = torch.block_diag(*PL_inv[None,:,:].repeat(batch_size,1,1))\n",
    "                    A_sb = torch.block_diag(*A_s.unsqueeze(0).repeat(batch_size,1,1))\n",
    "                    updated_c_1=  -A_sb@ prev_c_1 +  prev_c_1 @ At_  +  PL_b @ zt\n",
    "                    final_state = updated_c_1\n",
    "\n",
    "                    m1_vec[:,active] = updated_c_1.view(batch_size,3,-1)\n",
    "                    ne_vec[:,active] = final_state.view(batch_size,3,-1)\n",
    "\n",
    "                    # edge_index = current_edge_index.clone()\n",
    "\n",
    "                hidden_state_list.append(ne_vec)\n",
    "                logits = model.SeqClass(hidden_state_list[-1][:,-1]).view(-1)\n",
    "                # preds = ( logits> 0).float()\n",
    "                v_pred += (logits>0).to(int).tolist()\n",
    "                v_score += logits.tolist()\n",
    "                v_samples += y.tolist()\n",
    "\n",
    "        val_acc = accuracy_score(v_pred,v_samples)\n",
    "        auc = roc_auc_score(total_samples,total_score)\n",
    "        acc = accuracy_score(pred,total_samples)\n",
    "        \n",
    "        # print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f} |Train Acc: {acc:.4f}| Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        early_stopper(val_acc, model)\n",
    "        if early_stopper.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load(path,weights_only=True))\n",
    "    model.eval()\n",
    "    total_loss, total_score, total_samples = 0,[], []\n",
    "    hidden_state_list = []\n",
    "    pred = []\n",
    "    yt = []\n",
    "    for bid,batch in enumerate(test_loader):\n",
    "        src, dst = batch[\"src\"].to(device), batch[\"dst\"].to(device)\n",
    "        batch_size = src.shape[0]\n",
    "        batch_ids = torch.arange(src.shape[0],device=device)\n",
    "        x_src, x_dst, y = batch[\"x_src\"].to(device), batch[\"x_dst\"].to(device), batch[\"y\"].to(device)\n",
    "        src_b,dst_b = src+batch_ids[:,None],dst+batch_ids[:,None]\n",
    "        m1_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "        ne_vec = torch.zeros((batch_size,model.num_nodes,model.hidden_dim),device=model.device)\n",
    "        # edge_index = torch.stack([torch.arange(batch_size*model.num_nodes,device=model.device),torch.arange(batch_size*model.num_nodes,device=model.device)])\n",
    "        for t in range(src.shape[-1]):\n",
    "            src_t = src_b[:,t]\n",
    "            dst_t = dst_b[:,t]\n",
    "            # current_edge_index = to_undirected(torch.cat([edge_index,new_edges],dim=1))\n",
    "            active = torch.hstack([src[0,t],dst[0,t]])\n",
    "            x_t = torch.zeros((batch_size,3,model.input_dim),device=model.device)\n",
    "            # x_n =  torch.zeros((batch_size,2,model.hidden_dim),device=model.device)\n",
    "            \n",
    "            # Fill Data to Current Node\n",
    "            x_t[:,0]= x_src[:,t].unsqueeze(-1)\n",
    "            x_t[:,1]= x_dst[:,t].unsqueeze(-1)\n",
    "\n",
    "            if t>=1:\n",
    "                x_t[:,2]= x_src[:,t-1].unsqueeze(-1)\n",
    "                active = torch.hstack([active,src[0,t-1]])\n",
    "            else:\n",
    "                x_t[:,2]= x_src[:,0].unsqueeze(-1)\n",
    "                active = torch.hstack([active,src[0,0]])\n",
    "\n",
    "            prev_c_1= m1_vec[:,active].view((batch_size*3,-1))\n",
    "            x_batch = x_t.view(batch_size*3,-1)\n",
    "            zt = model.TuneInputSC(x_batch) # input Tuning / Selective Scan\n",
    "            # gate = model.B_gate_a(zt)\n",
    "            # ztn = F.sigmoid(gate)*zt\n",
    "            Bzt = zt #model.B1(zt)\n",
    "            # delta_1 = torch.ones((zt.shape[0],model.hidden_dim),device=model.device)\n",
    "            # A_cont_1 = -torch.exp(model.A_log_1) \n",
    "            # At_bar_1 = torch.exp(delta_1 * A_cont_1) \n",
    "            \n",
    "            At_ = Id - model.A_.T*delta\n",
    "\n",
    "            reg = 1\n",
    "            \n",
    "            # C_1 = ((Bzt * delta))[None]*t_weights[:,None,None] \n",
    "            # RHS_ = C_1@torch.matrix_exp((model.A_.T*delta)[None] * t_nodes[:,None,None])\n",
    "            \n",
    "            \n",
    "            PL_inv = torch.linalg.inv(In+reg*L_t)\n",
    "            PL_prev = In*(1+reg)\n",
    "            s  =  (In + PL_inv@PL_prev)\n",
    "            A_s= PL_inv@(reg*del_L)\n",
    "\n",
    "            PL_b = torch.block_diag(*PL_inv[None,:,:].repeat(batch_size,1,1))\n",
    "            # A_st = torch.matrix_exp(s*t_nodes[:,None,None])\n",
    "            A_sb = torch.block_diag(*A_s.unsqueeze(0).repeat(batch_size,1,1))\n",
    "            # A_stb = torch.stack([torch.block_diag(*s) for s in A_st[:,None,:,:].repeat(1,batch_size,1,1)])\n",
    "            # integral_1 = torch.sum(A_stb@PL_b[None,:,:]@RHS_,dim=0)\n",
    "\n",
    "            updated_c_1=  -A_sb@ prev_c_1 +  prev_c_1 @ At_  +  PL_b @ Bzt\n",
    "\n",
    "            u_2 =  zt+F.gelu(updated_c_1,approximate='tanh')# + zt approximate for faster results, maybe less accurate\n",
    "            final_state = updated_c_1\n",
    "            m1_vec[:,active] = updated_c_1.view(batch_size,3,-1)\n",
    "            ne_vec[:,active] = final_state.view(batch_size,3,-1)\n",
    "\n",
    "\n",
    "\n",
    "        hidden_state_list.append(ne_vec)\n",
    "        logits = model.SeqClass(hidden_state_list[-1][:,-1]).view(-1)\n",
    "        total_score += logits.tolist()\n",
    "        total_samples += y.tolist()\n",
    "        pred += (logits>0).to(int).tolist()\n",
    "\n",
    "    auc = roc_auc_score(total_samples,total_score)\n",
    "    best_acc = accuracy_score(total_samples,pred)\n",
    "    test_vals.append(best_acc)\n",
    "    print(f\" Test Acc: {best_acc:.4f} |Test AUC: {auc:.4f}\")\n",
    "\n",
    "print(f'{100*np.mean(test_vals)} $pm$ {100*np.std(test_vals)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
